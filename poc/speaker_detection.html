<!--
https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API
https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder
+ Google search for "javascript filter media stream data if audio level is low"
+ Copilot, fairly impressed with the code it generated
-->
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Basic Webpage</title>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/lamejs/1.2.1/lame.min.js"
      integrity="sha512-xT0S/xXvkrfkRXGBPlzZPCAncnMK5c1N7slRkToUbv8Z901aUEuKO84tLy8dWU+3ew4InFEN7TebPaVMy2npZw=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"></script>
  </head>
  <body>
    <h1>Welcome to the Audio Test webpage</h1>

    <div>
      <canvas id="waveform"></canvas>
      <canvas id="frequency"></canvas>
      <canvas id="volume"></canvas>
      <canvas id="thresholdSignal"></canvas>
      <canvas id="filteredSignal"></canvas>
    </div>
    <div>
      <button onclick="adjustThreshold(-1)">Decrease Threshold</button>
      <span id="thresholdValue">Threshold: 5</span>
      <button onclick="adjustThreshold(1)">Increase Threshold</button>
      <button onclick="stopAudio()">Stop</button>
      <button onclick="testAudio()">Start</button>
    </div>
    <div>
      <h2>Recorded MP3s</h2>
      <ul id="recordingsList"></ul>
    </div>
    <script>
      console.log("JavaScript executing");
      const WIDTH = 400;
      const HEIGHT = 100;
      const BAR_MARGIN = 1;
      const BAR_WIDTH_NOMINAL = 2.5;

      let VOLUME_THRESHOLD = 7;
      let audioContext;
      let animationFrameId;
      let mediaRecorder;
      let recordedChunks = [];
      let preRecordingBuffer = [];
      const PRE_RECORDING_DURATION = 100; // 100ms
      const mp3Blobs = []; // Global array to store mp3 blobs

      function adjustThreshold(amount) {
        VOLUME_THRESHOLD = Math.max(0, VOLUME_THRESHOLD + amount);
        document.getElementById(
          "thresholdValue"
        ).textContent = `Threshold: ${VOLUME_THRESHOLD}`;
      }

      function setCanvasDimensions() {
        const canvases = [
          "waveform",
          "frequency",
          "volume",
          "thresholdSignal",
          "filteredSignal",
        ];
        canvases.forEach((id) => {
          const canvas = document.getElementById(id);
          canvas.width = WIDTH;
          canvas.height = HEIGHT;
        });
      }

      function stopAudio() {
        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }
        if (animationFrameId) {
          cancelAnimationFrame(animationFrameId);
          animationFrameId = null;
        }
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
        }
      }

      function testAudio() {
        document.getElementById(
          "thresholdValue"
        ).textContent = `Threshold: ${VOLUME_THRESHOLD}`;
        setCanvasDimensions();

        // Get a handle to the canvas
        const waveformCanvas = document.getElementById("waveform");
        const waveformCanvasCtx = waveformCanvas.getContext("2d");

        const frequencyCanvas = document.getElementById("frequency");
        const frequencyCanvasCtx = frequencyCanvas.getContext("2d");

        const volumeCanvas = document.getElementById("volume");
        const volumeCanvasCtx = volumeCanvas.getContext("2d");
        const volumeData = [];

        const thresholdSignalCanvas =
          document.getElementById("thresholdSignal");
        const thresholdSignalCanvasCtx = thresholdSignalCanvas.getContext("2d");
        const thresholdSignalData = [];

        const filteredSignalCanvas = document.getElementById("filteredSignal");
        const filteredSignalCanvasCtx = filteredSignalCanvas.getContext("2d");
        const filteredSignalData = [];
        let aboveThreshold = false;
        let belowThresholdDuration = 0;

        // Draw the waveform
        waveformCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
        frequencyCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
        volumeCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
        thresholdSignalCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
        filteredSignalCanvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

        console.log("Button clicked!");
        navigator.mediaDevices
          .getUserMedia({ audio: { sampleRate: 44100 } })
          .then((stream) => {
            audioContext = new AudioContext();
            const source = audioContext.createMediaStreamSource(stream);
            const levelAnalyser = audioContext.createAnalyser();
            const waveformAnalyser = audioContext.createAnalyser();
            const frequencyAnalyser = audioContext.createAnalyser();

            source.connect(levelAnalyser);
            source.connect(waveformAnalyser);
            source.connect(frequencyAnalyser);

            const levelBufferLength = levelAnalyser.frequencyBinCount;
            const levelDataArray = new Uint8Array(levelBufferLength);

            waveformAnalyser.fftSize = 2048;
            const waveformBufferLength = waveformAnalyser.frequencyBinCount;
            const waveformDataArray = new Uint8Array(levelBufferLength);

            frequencyAnalyser.fftSize = 2048;
            const frequencyBufferLength = frequencyAnalyser.frequencyBinCount;
            const frequencyDataArray = new Uint8Array(levelBufferLength);

            const barWidth =
              (WIDTH / frequencyBufferLength) * BAR_WIDTH_NOMINAL;
            const MAX_VOLUME_DATA_POINTS = Math.ceil(
              WIDTH / (barWidth + BAR_MARGIN)
            );
            const MAX_THRESHOLD_SIGNAL_POINTS = Math.ceil(
              WIDTH / (barWidth + BAR_MARGIN)
            );
            const MAX_FILTERED_SIGNAL_POINTS = Math.ceil(
              WIDTH / (barWidth + BAR_MARGIN)
            );

            console.log("levelBufferLength:", levelBufferLength);
            console.log("barWidth:", barWidth);
            console.log("MAX_VOLUME_DATA_POINTS:", MAX_VOLUME_DATA_POINTS);
            console.log("Volume width:", barWidth * MAX_VOLUME_DATA_POINTS);

            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = (event) => {
              if (event.data.size > 0) {
                recordedChunks.push(event.data);
              }
            };
            mediaRecorder.onstop = async () => {
              if (!audioContext) return; // Ensure audioContext is initialized
              const audioBlob = new Blob(recordedChunks, { type: "audio/wav" });
              //const rawAudioUrl = URL.createObjectURL(audioBlob);
              //document.getElementById("rawAudioPlayback").src = rawAudioUrl;

              try {
                console.log("Encoding to MP3", audioBlob, recordedChunks);
                const arrayBuffer = await audioBlob.arrayBuffer();
                const audioBuffer = await new AudioContext().decodeAudioData(
                  arrayBuffer
                );
                console.log("Decoded audioBuffer:", audioBuffer);
                const mp3Blob = await encodeToMp3(audioBuffer);
                //const mp3AudioUrl = URL.createObjectURL(mp3Blob);
                //document.getElementById("mp3AudioPlayback").src = mp3AudioUrl;

                const url = URL.createObjectURL(mp3Blob);
                const li = document.createElement("li");
                const audio = document.createElement("audio");
                const downloadLink = document.createElement("a");

                audio.controls = true;
                audio.src = url;
                downloadLink.href = url;
                downloadLink.download = `recording_${mp3Blobs.length}.mp3`;
                downloadLink.textContent = `Download recording ${mp3Blobs.length}`;

                li.appendChild(audio);
                li.appendChild(downloadLink);
                document.getElementById("recordingsList").appendChild(li);
              } catch (error) {
                console.error("Error encoding MP3:", error);
              }
            };

            function processAudio() {
              levelAnalyser.getByteFrequencyData(levelDataArray);

              // Calculate average volume
              let sum = 0;
              for (let i = 0; i < levelBufferLength; i++) {
                sum += levelDataArray[i];
              }
              const average = sum / levelBufferLength;

              // Store the average volume level
              if (volumeData.length >= MAX_VOLUME_DATA_POINTS) {
                volumeData.shift();
              }
              volumeData.push(average);

              // Store the threshold signal
              const thresholdSignal = average > VOLUME_THRESHOLD ? 255 : 0;
              if (thresholdSignalData.length >= MAX_THRESHOLD_SIGNAL_POINTS) {
                thresholdSignalData.shift();
              }
              thresholdSignalData.push(thresholdSignal);

              // Store the filtered signal
              if (average > VOLUME_THRESHOLD) {
                aboveThreshold = true;
                belowThresholdDuration = 0;
              } else {
                belowThresholdDuration += 16.67; // Approximate duration of one frame at 60 FPS
                if (belowThresholdDuration >= 500) {
                  aboveThreshold = false;
                }
              }

              const filteredSignal = aboveThreshold ? 255 : 0;
              if (filteredSignalData.length >= MAX_FILTERED_SIGNAL_POINTS) {
                filteredSignalData.shift();
              }
              filteredSignalData.push(filteredSignal);

              // Manage pre-recording buffer
              if (preRecordingBuffer.length >= PRE_RECORDING_DURATION / 16.67) {
                preRecordingBuffer.shift();
              }
              preRecordingBuffer.push(filteredSignal);

              // Start or stop recording based on filtered signal
              if (filteredSignal && mediaRecorder.state === "inactive") {
                // TODO: fix this, it inserts garbage data, likely because it's not combining the pre-recording buffer with the recorded chunks
                //recordedChunks = preRecordingBuffer.slice(); // Include pre-recording buffer
                recordedChunks = [];
                mediaRecorder.start();
              } else if (
                !filteredSignal &&
                mediaRecorder.state === "recording"
              ) {
                mediaRecorder.stop();
              }

              animationFrameId = requestAnimationFrame(processAudio);
            }

            function drawWaveform() {
              const drawVisual = requestAnimationFrame(drawWaveform);
              waveformAnalyser.getByteTimeDomainData(waveformDataArray);

              waveformCanvasCtx.fillStyle = "rgb(200 200 200)";
              waveformCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

              waveformCanvasCtx.lineWidth = 2;
              waveformCanvasCtx.strokeStyle = "rgb(0 0 0)";
              waveformCanvasCtx.beginPath();

              const sliceWidth = WIDTH / waveformBufferLength;
              let x = 0;
              for (let i = 0; i < waveformBufferLength; i++) {
                const v = waveformDataArray[i] / 128.0;
                const y = v * (HEIGHT / 2);

                if (i === 0) {
                  waveformCanvasCtx.moveTo(x, y);
                } else {
                  waveformCanvasCtx.lineTo(x, y);
                }

                x += sliceWidth;
              }

              waveformCanvasCtx.lineTo(WIDTH, HEIGHT / 2);
              waveformCanvasCtx.stroke();

              // Draw the VOLUME_THRESHOLD bars
              waveformCanvasCtx.lineWidth = 1;
              waveformCanvasCtx.strokeStyle = "rgb(255 0 0)";
              waveformCanvasCtx.beginPath();
              const thresholdYPositive =
                HEIGHT / 2 - ((VOLUME_THRESHOLD / 255.0) * HEIGHT) / 2;
              const thresholdYNegative =
                HEIGHT / 2 + ((VOLUME_THRESHOLD / 255.0) * HEIGHT) / 2;
              waveformCanvasCtx.moveTo(0, thresholdYPositive);
              waveformCanvasCtx.lineTo(WIDTH, thresholdYPositive);
              waveformCanvasCtx.moveTo(0, thresholdYNegative);
              waveformCanvasCtx.lineTo(WIDTH, thresholdYNegative);
              waveformCanvasCtx.stroke();
            }

            function drawFrequency() {
              const drawVisual = requestAnimationFrame(drawFrequency);
              frequencyAnalyser.getByteFrequencyData(frequencyDataArray);

              frequencyCanvasCtx.fillStyle = "rgb(200 200 200)";
              frequencyCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

              let barHeight;
              let x = 0;
              for (let i = 0; i < frequencyBufferLength; i++) {
                barHeight = frequencyDataArray[i] / 2;

                frequencyCanvasCtx.fillStyle = "rgb(0 0 0)";
                frequencyCanvasCtx.fillRect(
                  x,
                  HEIGHT - barHeight / 2,
                  barWidth,
                  barHeight
                );

                x += barWidth + BAR_MARGIN;
              }

              // Draw the VOLUME_THRESHOLD line
              frequencyCanvasCtx.strokeStyle = "rgb(255 0 0)";
              frequencyCanvasCtx.beginPath();
              const thresholdY = HEIGHT - (VOLUME_THRESHOLD / 255.0) * HEIGHT;
              frequencyCanvasCtx.moveTo(0, thresholdY);
              frequencyCanvasCtx.lineTo(WIDTH, thresholdY);
              frequencyCanvasCtx.stroke();
            }

            function drawVolume() {
              const drawVisual = requestAnimationFrame(drawVolume);

              volumeCanvasCtx.fillStyle = "rgb(200 200 200)";
              volumeCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

              //const barWidth = (WIDTH / frequencyBufferLength) * 2.5;
              let x = 0;
              for (let i = 0; i < volumeData.length; i++) {
                const barHeight = (volumeData[i] / 255.0) * HEIGHT;

                volumeCanvasCtx.fillStyle = "rgb(0 0 0)";
                volumeCanvasCtx.fillRect(
                  x,
                  HEIGHT - barHeight,
                  barWidth,
                  barHeight
                );

                x += barWidth + BAR_MARGIN;
              }

              // Draw the VOLUME_THRESHOLD line
              volumeCanvasCtx.strokeStyle = "rgb(255 0 0)";
              volumeCanvasCtx.beginPath();
              const thresholdY = HEIGHT - (VOLUME_THRESHOLD / 255.0) * HEIGHT;
              volumeCanvasCtx.moveTo(0, thresholdY);
              volumeCanvasCtx.lineTo(WIDTH, thresholdY);
              volumeCanvasCtx.stroke();
            }

            function drawThresholdSignal() {
              const drawVisual = requestAnimationFrame(drawThresholdSignal);

              thresholdSignalCanvasCtx.fillStyle = "rgb(200 200 200)";
              thresholdSignalCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

              let x = 0;
              for (let i = 0; i < thresholdSignalData.length; i++) {
                const barHeight = (thresholdSignalData[i] / 255.0) * HEIGHT;

                thresholdSignalCanvasCtx.fillStyle = "rgb(0 0 0)";
                thresholdSignalCanvasCtx.fillRect(
                  x,
                  HEIGHT - barHeight,
                  barWidth,
                  barHeight
                );

                x += barWidth + BAR_MARGIN;
              }
            }

            function drawFilteredSignal() {
              const drawVisual = requestAnimationFrame(drawFilteredSignal);

              filteredSignalCanvasCtx.fillStyle = "rgb(200 200 200)";
              filteredSignalCanvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

              let x = 0;
              for (let i = 0; i < filteredSignalData.length; i++) {
                const barHeight = (filteredSignalData[i] / 255.0) * HEIGHT;

                filteredSignalCanvasCtx.fillStyle = "rgb(0 0 0)";
                filteredSignalCanvasCtx.fillRect(
                  x,
                  HEIGHT - barHeight,
                  barWidth,
                  barHeight
                );

                x += barWidth + BAR_MARGIN;
              }
            }

            processAudio();
            drawWaveform();
            drawFrequency();
            drawVolume();
            drawThresholdSignal();
            drawFilteredSignal();
          })
          .catch((error) => {
            console.error("Error accessing media stream:", error);
          });
      }
      async function encodeToMp3(audioBuffer) {
        const startTime = Date.now();
        const channels = 1; // Assuming mono audio
        const sampleRate = audioBuffer.sampleRate;
        const audioData = audioBuffer.getChannelData(0);

        //convert the audio data to 16 bit pcm
        const samples = new Int16Array(audioData.length);
        for (let i = 0; i < audioData.length; i++) {
          samples[i] = audioData[i] * 0x7fff;
        }
        const wav = lamejs.WavHeader.readHeader(new DataView(samples.buffer));

        //const mp3Blob = encodeAudio(samples, channels, sampleRate);
        //return mp3Blob;

        console.log("Encoding to MP3 with sampleRate:", sampleRate);
        console.log("Number of samples:", samples.length);

        const kbps = 128;
        const mp3encoder = new lamejs.Mp3Encoder(channels, sampleRate, kbps);
        const sampleBlockSize = 1152;
        let sampleChunk;
        const mp3Data = [];

        for (let i = 0; i < samples.length; i += sampleBlockSize) {
          sampleChunk = samples.subarray(i, i + sampleBlockSize);
          const mp3buf = mp3encoder.encodeBuffer(sampleChunk);
          if (mp3buf.length > 0) {
            mp3Data.push(mp3buf);
          }
        }
        const endTimestamp = Date.now();
        console.log("Encoding time:", endTimestamp - startTime, "ms");
        return new Blob(mp3Data, { type: "audio/mp3" });
      }
    </script>
  </body>
</html>
